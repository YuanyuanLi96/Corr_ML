{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d0be11-494d-4964-a05f-fed4898a9c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "518a8f2c-7765-447f-89de-1254d75832db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af75681b-bff4-41ef-a7f7-036506258354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from llm_main.feature_engineer import DataFrameSplitter\n",
    "from llm_main.prompt_engineer import PromptGenerator\n",
    "from llm_main.model_base import QuantizedBaseModelInitializer\n",
    "from llm_main.predict import ModelPredictor\n",
    "from llm_main.evaluation import ModelEvaluator\n",
    "from llm_main.train_with_fine_tuning import PEFTModelTrainer\n",
    "from llm_main.model_fine_tune import ModelReloader\n",
    "from datasets import load_dataset\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "075333b1-c20e-4048-8fe8-15a0e3e61cd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 Model training and testing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a6b4df2-a2a4-426a-bff2-8bf3f39ed05b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clear_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def Preprocess_data(data_type, local=True, label_col=\"label\", text_col=\"text\", target=\"sentiment\",version=None,split=\"train\"):\n",
    "    #Every dataset has 2 columns with \"target\" and \"text\"\n",
    "    # Check if the folder exists\n",
    "    folder_path='data/'+data_type\n",
    "    if not os.path.exists(folder_path):\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path)\n",
    "    if local:\n",
    "        #sentiment of news: https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis/input\n",
    "        file_path=folder_path+'/all_data.csv'\n",
    "        df = pd.read_csv(file_path, encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "    else:\n",
    "        if version is None:\n",
    "            df = load_dataset(data_type, split=split)\n",
    "        else:\n",
    "            df = load_dataset(data_type, version, split=split)\n",
    "\n",
    "        df=df.to_pandas()\n",
    "        df=df[[label_col,text_col]]\n",
    "        df.columns = [target,\"text\"]\n",
    "        \n",
    "    splitter = DataFrameSplitter(df, train_size=300)\n",
    "\n",
    "    # Perform the split to obtain train, test, and eval sets\n",
    "    X_train_df, X_test_df, X_eval_df = splitter.split()\n",
    "    X_train_df.to_csv(folder_path+\"/X_train_df.csv\", index=False)\n",
    "    X_test_df.to_csv(folder_path+\"/X_test_df.csv\", index=False)\n",
    "    X_eval_df.to_csv(folder_path+\"/X_eval_df.csv\", index=False)\n",
    "\n",
    "def read_dataset(data_type):\n",
    "    folder_path='data/'+data_type\n",
    "    X_train_df=pd.read_csv(folder_path+\"/X_train_df.csv\")\n",
    "    X_test_df=pd.read_csv(folder_path+\"/X_test_df.csv\")\n",
    "    X_eval_df=pd.read_csv(folder_path+\"/X_eval_df.csv\")\n",
    "    return X_train_df, X_test_df, X_eval_df\n",
    "\n",
    "def training_prompt(X_train_df, X_test_df, X_eval_df):\n",
    "    target=X_train_df.columns[0]\n",
    "    prompt_generator = PromptGenerator(target)\n",
    "    # Generate training and validation prompts\n",
    "    X_train_prompt = prompt_generator.generate_dataframe_prompts(X_train_df, prompt_type='train')\n",
    "    X_eval_prompt = prompt_generator.generate_dataframe_prompts(X_eval_df, prompt_type='train')\n",
    "    X_test_prompt = prompt_generator.generate_dataframe_prompts(X_test_df, prompt_type='test')\n",
    "    return X_train_prompt, X_test_prompt, X_eval_prompt\n",
    "  \n",
    "\n",
    "def fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt,target_modules=\"all-linear\"):\n",
    "    clear_gpu()\n",
    "    # Create an instance of QuantizedBaseModelInitializer\n",
    "    initializer = QuantizedBaseModelInitializer(base_model_name)\n",
    "    # Initialize the model and tokenizer with quantization\n",
    "    base_model, tokenizer = initializer.initialize()\n",
    "    train_data = Dataset.from_pandas(X_train_prompt)\n",
    "    eval_data = Dataset.from_pandas(X_eval_prompt)\n",
    "    trained_model_name = \"trained_model/\"+data+\"/\"+base_model_name\n",
    "    os.makedirs(trained_model_name, exist_ok=True)\n",
    "    trainer = PEFTModelTrainer(base_model, tokenizer, train_data, eval_data, model_name=trained_model_name, target_modules=target_modules)\n",
    "    # Start the training process\n",
    "    trainer.train_model()\n",
    "    print(\"Model training is completed\")\n",
    "    del base_model, X_train_prompt\n",
    "    return trainer\n",
    "\n",
    "def load_model(base_model_name, data):\n",
    "    clear_gpu()\n",
    "    trained_model_name = \"trained_model/\"+data+\"/\"+base_model_name\n",
    "    reloader = ModelReloader(base_model_name, trained_model_name)\n",
    "    model, tokenizer = reloader.reload()\n",
    "    return model, tokenizer\n",
    "\n",
    "def evaluate_model(model, tokenizer, base_model_name, data,X_test_prompt,y_true):\n",
    "    clear_gpu()\n",
    "    # trained_model_name = \"trained_model/\"+data+\"/\"+base_model_name\n",
    "    # reloader = ModelReloader(base_model_name, trained_model_name)\n",
    "    # model, tokenizer = reloader.reload()\n",
    "    labels=set(y_true)\n",
    "    predictor = ModelPredictor(model, tokenizer, labels)\n",
    "    y_pred = predictor.predict(X_test_prompt)\n",
    "    evaluator = ModelEvaluator()\n",
    "    y_true_label, y_pred_label=evaluator.evaluate(y_true, y_pred)\n",
    "    print(\"Model evaluation is completed\")\n",
    "    errors=(y_true_label!= y_pred_label).astype(int)\n",
    "    method_name=data+\"/\"+base_model_name\n",
    "    os.makedirs(\"result/\"+method_name, exist_ok=True)\n",
    "    error_df=pd.DataFrame({method_name:errors})\n",
    "    error_df.to_csv(\"result/\"+method_name+\"/errors.csv\", index=False)\n",
    "    del model, X_test_prompt\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# def load_test_loss(data_type, version=0):\n",
    "#     test_error=pd.read_csv( \"test_loss/sklearn_models_\"+ data_type +\"_\"+ str(version)+ \".csv\")\n",
    "#     test_error_nn=pd.read_csv( \"test_loss/nn_models_\"+ data_type + \"_\"+ str(version)+\".csv\")\n",
    "#     return pd.concat([test_error, test_error_nn], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7731143-b67d-4cd4-aa76-1d6321610def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e8165be-e834-4100-a9f2-d70a93161cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# target=\"review_sentiment\"\n",
    "# data=\"fancyzhx/amazon_polarity\"\n",
    "# clear_gpu()\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"content\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8cb27c6-e18e-48fc-844c-e6d896015044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target=\"sentiment\"\n",
    "data=\"takala/financial_phrasebank\"\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"sentence\", target=target, version='sentences_50agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00538d58-55eb-492a-9b23-b5caf7cef548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target=\"finance_sentiment\"\n",
    "data=\"zeroshot/twitter-financial-news-sentiment\"\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"text\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ca71494-391f-492e-8482-5cc63a4ed5f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target=\"emotion6\"\n",
    "data=\"AdamCodd/emotion-balanced\"\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"text\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90dcde38-2d2c-43c8-a4ea-8ba3a9289103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target=\"emotion7\"\n",
    "data=\"ma2za/many_emotions\"\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"text\", target=target,version=\"raw\",split=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5cd76db-2879-49de-a6ee-0ea6c80626dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target=\"news_class\"\n",
    "data=\"fancyzhx/ag_news\"\n",
    "#Preprocess_data(data,local=False, label_col=\"label\", text_col=\"text\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af5b4d5-3562-4695-bc8d-ed3e33df673b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_df, X_test_df, X_eval_df=read_dataset(data)\n",
    "y_true = X_test_df[target].astype(str)\n",
    "X_train_prompt, X_test_prompt, X_eval_prompt=training_prompt(X_train_df, X_test_df, X_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cf36144-9580-4632-9fe4-dc4a8def79d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read dataset and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90dcf12d-6196-45d4-8b47-ca2d7c5957b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_prompt[\"text\"][101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2785b8b9-a4df-409c-84f4-39ef423dc80a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #test LLM for a single prompt\n",
    "# clear_gpu()\n",
    "# base_model_name= \"NousResearch/Llama-2-7b-hf\"\n",
    "# base_model=AutoModelForCausalLM.from_pretrained(\n",
    "#             base_model_name,\n",
    "#             torch_dtype='auto',  # Set torch dtype to 'auto' for automatic handling\n",
    "#             device_map=\"auto\",  # Automatic device mapping for optimal placement\n",
    "#             # quantization_config=bnb_config,  # Uncomment and adjust if quantization is needed\n",
    "#         )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#             base_model_name,\n",
    "#             trust_remote_code=True,  # Enable loading custom/remote tokenizers\n",
    "#         )\n",
    "# tokenizer.pad_token = tokenizer.eos_token  # Set pad token\n",
    "# tokenizer.padding_side = \"right\" \n",
    "# pipe=pipeline(task=\"text-generation\", \n",
    "#                              model=base_model, \n",
    "#                              tokenizer=tokenizer, \n",
    "#                              max_new_tokens=6,  # Number of tokens to generate\n",
    "#                              temperature=0.001   # Sampling temperature\n",
    "#                             )\n",
    "# prompt=X_test_prompt[\"text\"][277]\n",
    "# result = pipe(prompt)\n",
    "# answer = result[0]['generated_text'].split(\"] =\")[1].strip()\n",
    "# answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecd61e1c-b30d-4a87-8830-9b2b279c085d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "base_model_name = \"NousResearch/Llama-2-7b-hf\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer, base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf93867-c34c-4c6c-ad06-180566c99759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer, base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c08f5c0a-ceb5-4487-99cd-b6432d801119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"bigscience/bloom-7b1\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "#y_true_label, y_pred_label=evaluate_model(base_model_name, data,X_test_prompt,y_true)\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer, base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3207137-32c1-4c27-9ecd-7c48e0c14f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"tiiuae/falcon-7b\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer, base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23eb726a-1317-4b00-8070-b8b54bdd83ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer, base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662ad0bb-b7d2-4186-9307-a9d1a8ac1e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"CohereForAI/aya-23-8B\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer,base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7984311e-14dd-4f61-9cdd-c9bee1176464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"Qwen/Qwen2-7B\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer,base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc54e24c-9e33-4934-8c5b-d30222e3e491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clear_gpu()\n",
    "del trainer\n",
    "base_model_name = \"microsoft/phi-2\"\n",
    "trainer=fine_tune(base_model_name, data, X_train_prompt, X_eval_prompt)\n",
    "#Evaluate model on test set\n",
    "y_pred=evaluate_model(trainer.model,trainer.tokenizer,base_model_name, data,X_test_prompt,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3900af4e-ff9e-4d16-a020-42104ebbda42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "training_pipeline_LLM",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "python_GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
